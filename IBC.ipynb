{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "276e78bb-f757-41b7-a929-740cba58c6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d00d8dfd-5994-49c8-9e9b-3cc1abbcb55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 23:57:42.278766: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-08 23:58:18.643124: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.10.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from PushTImageEnv import PushTImageEnv\n",
    "from data_vision import PushTImageDataset, unnormalize_data, normalize_data\n",
    "import torch as t\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from conditional_unet1d import ConditionalUnet1D\n",
    "from transformer_for_diffusion import TransformerForDiffusion\n",
    "from diffusers.training_utils import EMAModel\n",
    "from diffusers import DDPMScheduler, DDIMScheduler\n",
    "from diffusers.optimization import get_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "import collections\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81b86985-9f00-45fb-a9f8-38161ad3a2eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'diffusion_policy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusion_policy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnormalizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearNormalizer\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusion_policy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_lowdim_policy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseLowdimPolicy\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'diffusion_policy'"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from diffusion_policy.model.common.normalizer import LinearNormalizer\n",
    "from diffusion_policy.policy.base_lowdim_policy import BaseLowdimPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e9e45c4-34b0-4520-bfa5-70d4d04c2dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f17217b0-bc18-4dc9-b41d-584f20c0cc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb8a08-6344-42cb-a6e6-f491bd0fc699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class IbcDfoLowdimPolicy(BaseLowdimPolicy):\n",
    "    def __init__(self,\n",
    "            horizon, \n",
    "            obs_dim, \n",
    "            action_dim, \n",
    "            n_action_steps, \n",
    "            n_obs_steps,\n",
    "            dropout=0.1,\n",
    "            train_n_neg=128,\n",
    "            pred_n_iter=5,\n",
    "            pred_n_samples=16384,\n",
    "            kevin_inference=False,\n",
    "            andy_train=False\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        in_action_channels = action_dim * n_action_steps\n",
    "        in_obs_channels = obs_dim * n_obs_steps\n",
    "        in_channels = in_action_channels + in_obs_channels\n",
    "        mid_channels = 1024\n",
    "        out_channels = 1\n",
    "\n",
    "        self.dense0 = nn.Linear(in_features=in_channels, out_features=mid_channels)\n",
    "        self.drop0 = nn.Dropout(dropout)\n",
    "        self.dense1 = nn.Linear(in_features=mid_channels, out_features=mid_channels)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.dense2 = nn.Linear(in_features=mid_channels, out_features=mid_channels)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "        self.dense3 = nn.Linear(in_features=mid_channels, out_features=mid_channels)\n",
    "        self.drop3 = nn.Dropout(dropout)\n",
    "        self.dense4 = nn.Linear(in_features=mid_channels, out_features=out_channels)\n",
    "\n",
    "        self.normalizer = LinearNormalizer()\n",
    "\n",
    "        self.train_n_neg = train_n_neg\n",
    "        self.pred_n_iter = pred_n_iter\n",
    "        self.pred_n_samples = pred_n_samples\n",
    "        self.obs_dim = obs_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.n_obs_steps = n_obs_steps\n",
    "        self.n_action_steps = n_action_steps\n",
    "        self.horizon = horizon\n",
    "        self.kevin_inference = kevin_inference\n",
    "        self.andy_train = andy_train\n",
    "    \n",
    "    def forward(self, obs, action):\n",
    "        B, N, Ta, Da = action.shape\n",
    "        B, To, Do = obs.shape\n",
    "        s = obs.reshape(B,1,-1).expand(-1,N,-1)\n",
    "        x = torch.cat([s, action.reshape(B,N,-1)], dim=-1).reshape(B*N,-1)\n",
    "        x = self.drop0(torch.relu(self.dense0(x)))\n",
    "        x = self.drop1(torch.relu(self.dense1(x)))\n",
    "        x = self.drop2(torch.relu(self.dense2(x)))\n",
    "        x = self.drop3(torch.relu(self.dense3(x)))\n",
    "        x = self.dense4(x)\n",
    "        x = x.reshape(B,N)\n",
    "        return x\n",
    "\n",
    "    # ========= inference  ============\n",
    "    def predict_action(self, obs_dict: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        obs_dict: must include \"obs\" key\n",
    "        result: must include \"action\" key\n",
    "        \"\"\"\n",
    "\n",
    "        assert 'obs' in obs_dict\n",
    "        assert 'past_action' not in obs_dict # not implemented yet\n",
    "        nobs = self.normalizer['obs'].normalize(obs_dict['obs'])\n",
    "        B, _, Do = nobs.shape\n",
    "        To = self.n_obs_steps\n",
    "        assert Do == self.obs_dim\n",
    "        T = self.horizon\n",
    "        Da = self.action_dim\n",
    "        Ta = self.n_action_steps\n",
    "\n",
    "        # only take necessary obs\n",
    "        this_obs = nobs[:,:To]\n",
    "        naction_stats = self.get_naction_stats()\n",
    "\n",
    "        # first sample\n",
    "        action_dist = torch.distributions.Uniform(\n",
    "            low=naction_stats['min'],\n",
    "            high=naction_stats['max']\n",
    "        )\n",
    "        samples = action_dist.sample((B, self.pred_n_samples, Ta)).to(\n",
    "            dtype=this_obs.dtype)\n",
    "        # (B, N, Ta, Da)\n",
    "\n",
    "        if self.kevin_inference:\n",
    "            # kevin's implementation\n",
    "            noise_scale = 3e-2\n",
    "            for i in range(self.pred_n_iter):\n",
    "                # Compute energies.\n",
    "                logits = self.forward(this_obs, samples)\n",
    "                probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "                # Resample with replacement.\n",
    "                idxs = torch.multinomial(probs, self.pred_n_samples, replacement=True)\n",
    "                samples = samples[torch.arange(samples.size(0)).unsqueeze(-1), idxs]\n",
    "\n",
    "                # Add noise and clip to target bounds.\n",
    "                samples = samples + torch.randn_like(samples) * noise_scale\n",
    "                samples = samples.clamp(min=naction_stats['min'], max=naction_stats['max'])\n",
    "\n",
    "            # Return target with highest probability.\n",
    "            logits = self.forward(this_obs, samples)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            best_idxs = probs.argmax(dim=-1)\n",
    "            acts_n = samples[torch.arange(samples.size(0)), best_idxs, :]\n",
    "        else:\n",
    "            # andy's implementation\n",
    "            zero = torch.tensor(0, device=self.device)\n",
    "            resample_std = torch.tensor(3e-2, device=self.device)\n",
    "            for i in range(self.pred_n_iter):\n",
    "                # Forward pass.\n",
    "                logits = self.forward(this_obs, samples) # (B, N)\n",
    "                prob = torch.softmax(logits, dim=-1)\n",
    "\n",
    "                if i < (self.pred_n_iter - 1):\n",
    "                    idxs = torch.multinomial(prob, self.pred_n_samples, replacement=True)\n",
    "                    samples = samples[torch.arange(samples.size(0)).unsqueeze(-1), idxs]\n",
    "                    samples += torch.normal(zero, resample_std, size=samples.shape, device=self.device)\n",
    "\n",
    "            # Return one sample per x in batch.\n",
    "            idxs = torch.multinomial(prob, num_samples=1, replacement=True)\n",
    "            acts_n = samples[torch.arange(samples.size(0)).unsqueeze(-1), idxs].squeeze(1)\n",
    "\n",
    "        action = self.normalizer['action'].unnormalize(acts_n)\n",
    "        result = {\n",
    "            'action': action\n",
    "        }\n",
    "        return result\n",
    "\n",
    "    # ========= training  ============\n",
    "    def set_normalizer(self, normalizer: LinearNormalizer):\n",
    "        self.normalizer.load_state_dict(normalizer.state_dict())\n",
    "\n",
    "    def compute_loss(self, batch):\n",
    "        # normalize input\n",
    "        assert 'valid_mask' not in batch\n",
    "        nbatch = self.normalizer.normalize(batch)\n",
    "        nobs = nbatch['obs']\n",
    "        naction = nbatch['action']\n",
    "\n",
    "        # shapes\n",
    "        Do = self.obs_dim\n",
    "        Da = self.action_dim\n",
    "        To = self.n_obs_steps\n",
    "        Ta = self.n_action_steps\n",
    "        T = self.horizon\n",
    "        B = naction.shape[0]\n",
    "\n",
    "        this_obs = nobs[:,:To]\n",
    "        start = To - 1\n",
    "        end = start + Ta\n",
    "        this_action = naction[:,start:end]\n",
    "\n",
    "        # Small additive noise to true positives.\n",
    "        this_action += torch.normal(mean=0, std=1e-4,\n",
    "            size=this_action.shape,\n",
    "            dtype=this_action.dtype,\n",
    "            device=this_action.device)\n",
    "\n",
    "        # Sample negatives: (B, train_n_neg, Ta, Da)\n",
    "        naction_stats = self.get_naction_stats()\n",
    "        action_dist = torch.distributions.Uniform(\n",
    "            low=naction_stats['min'],\n",
    "            high=naction_stats['max']\n",
    "        )\n",
    "        samples = action_dist.sample((B, self.train_n_neg, Ta)).to(\n",
    "            dtype=this_action.dtype)\n",
    "        action_samples = torch.cat([\n",
    "            this_action.unsqueeze(1), samples], dim=1)\n",
    "        # (B, train_n_neg+1, Ta, Da)\n",
    "\n",
    "        if self.andy_train:\n",
    "            # Get onehot labels\n",
    "            labels = torch.zeros(action_samples.shape[:2], \n",
    "                dtype=this_action.dtype, device=this_action.device)\n",
    "            labels[:,0] = 1\n",
    "            logits = self.forward(this_obs, action_samples)\n",
    "            # (B, N)\n",
    "            logits = torch.log_softmax(logits, dim=-1)\n",
    "            loss = -torch.mean(torch.sum(logits * labels, axis=-1))\n",
    "        else:\n",
    "            labels = torch.zeros((B,),dtype=torch.int64, device=this_action.device)\n",
    "            # training\n",
    "            logits = self.forward(this_obs, action_samples)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def get_naction_stats(self):\n",
    "        Da = self.action_dim\n",
    "        naction_stats = self.normalizer['action'].get_output_stats()\n",
    "        repeated_stats = dict()\n",
    "        for key, value in naction_stats.items():\n",
    "            assert len(value.shape) == 1\n",
    "            n_repeats = Da // value.shape[0]\n",
    "            assert value.shape[0] * n_repeats == Da\n",
    "            repeated_stats[key] = value.repeat(n_repeats)\n",
    "        return repeated_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
