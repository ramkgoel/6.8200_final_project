{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7beb7b70-5111-44ac-9736-a6c90536dadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nohup: ignoring input and redirecting stderr to stdout\n"
     ]
    }
   ],
   "source": [
    "!nohup python hyperparam_tuning.py 1 > logs/1.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d8632f-d95c-46b6-b6bc-84f51602099a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8d1b4c9-4fdb-4bc7-8b7a-d0c65ea477bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PushTImageEnv import PushTImageEnv\n",
    "from data_vision import PushTImageDataset, unnormalize_data, normalize_data\n",
    "import torch as t\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from conditional_unet1d import ConditionalUnet1D\n",
    "from transformer_for_diffusion import TransformerForDiffusion\n",
    "from diffusers.training_utils import EMAModel\n",
    "from diffusers import DDPMScheduler, DDIMScheduler\n",
    "from diffusers.optimization import get_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_model(\n",
    "        obs_horizon=2,\n",
    "        device=\"cuda:0\",\n",
    "        pred_horizon=64,\n",
    "        action_horizon=8,\n",
    "        diffusion_timesteps=100,\n",
    "        resnet=\"resnet18\"\n",
    "    ):\n",
    "\n",
    "    def get_resnet(name:str, weights=None, **kwargs) -> nn.Module:\n",
    "        \"\"\"\n",
    "        name: resnet18, resnet34, resnet50\n",
    "        weights: \"IMAGENET1K_V1\", None\n",
    "        \"\"\"\n",
    "        # Use standard ResNet implementation from torchvision\n",
    "        func = getattr(torchvision.models, name)\n",
    "        resnet = func(weights=weights, **kwargs)\n",
    "\n",
    "        # remove the final fully connected layer\n",
    "        # for resnet18, the output dim should be 512\n",
    "        resnet.fc = torch.nn.Identity()\n",
    "        return resnet\n",
    "\n",
    "\n",
    "    def replace_submodules(\n",
    "            root_module: nn.Module, \n",
    "            predicate, \n",
    "            func) -> nn.Module:\n",
    "        \"\"\"\n",
    "        Replace all submodules selected by the predicate with\n",
    "        the output of func.\n",
    "\n",
    "        predicate: Return true if the module is to be replaced.\n",
    "        func: Return new module to use.\n",
    "        \"\"\"\n",
    "        if predicate(root_module):\n",
    "            return func(root_module)\n",
    "\n",
    "        bn_list = [k.split('.') for k, m \n",
    "            in root_module.named_modules(remove_duplicate=True) \n",
    "            if predicate(m)]\n",
    "        for *parent, k in bn_list:\n",
    "            parent_module = root_module\n",
    "            if len(parent) > 0:\n",
    "                parent_module = root_module.get_submodule('.'.join(parent))\n",
    "            if isinstance(parent_module, nn.Sequential):\n",
    "                src_module = parent_module[int(k)]\n",
    "            else:\n",
    "                src_module = getattr(parent_module, k)\n",
    "            tgt_module = func(src_module)\n",
    "            if isinstance(parent_module, nn.Sequential):\n",
    "                parent_module[int(k)] = tgt_module\n",
    "            else:\n",
    "                setattr(parent_module, k, tgt_module)\n",
    "        # verify that all modules are replaced\n",
    "        bn_list = [k.split('.') for k, m \n",
    "            in root_module.named_modules(remove_duplicate=True) \n",
    "            if predicate(m)]\n",
    "        assert len(bn_list) == 0\n",
    "        return root_module\n",
    "\n",
    "    def replace_bn_with_gn(\n",
    "        root_module: nn.Module, \n",
    "        features_per_group: int=16) -> nn.Module:\n",
    "        \"\"\"\n",
    "        Relace all BatchNorm layers with GroupNorm.\n",
    "        \"\"\"\n",
    "        replace_submodules(\n",
    "            root_module=root_module,\n",
    "            predicate=lambda x: isinstance(x, nn.BatchNorm2d),\n",
    "            func=lambda x: nn.GroupNorm(\n",
    "                num_groups=x.num_features//features_per_group, \n",
    "                num_channels=x.num_features)\n",
    "        )\n",
    "        return root_module\n",
    "\n",
    "    # download demonstration data from Google Drive\n",
    "    dataset_path = \"pusht_cchi_v7_replay.zarr\"\n",
    "\n",
    "    # parameters\n",
    "    # pred_horizon = 16\n",
    "    # obs_horizon = 2\n",
    "    # action_horizon = 8\n",
    "    #|o|o|                             observations: 2\n",
    "    #| |a|a|a|a|a|a|a|a|               actions executed: 8\n",
    "    #|p|p|p|p|p|p|p|p|p|p|p|p|p|p|p|p| actions predicted: 16\n",
    "\n",
    "    # create dataset from file\n",
    "    dataset = PushTImageDataset(\n",
    "        dataset_path=dataset_path,\n",
    "        pred_horizon=pred_horizon,\n",
    "        obs_horizon=obs_horizon,\n",
    "        action_horizon=action_horizon\n",
    "    )\n",
    "\n",
    "    stats = dataset.stats\n",
    "\n",
    "    # create dataloader\n",
    "    dataloader = t.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=256,\n",
    "        num_workers=1,\n",
    "        shuffle=True,\n",
    "        # accelerate cpu-gpu transfer\n",
    "        pin_memory=True,\n",
    "        # don't kill worker process afte each epoch\n",
    "        persistent_workers=True \n",
    "    )\n",
    "\n",
    "    # construct ResNet18 encoder\n",
    "    # if you have multiple camera views, use seperate encoder weights for each view.\n",
    "    vision_encoder = get_resnet('resnet18')\n",
    "\n",
    "    # IMPORTANT!\n",
    "    # replace all BatchNorm with GroupNorm to work with EMA\n",
    "    # performance will tank if you forget to do this!\n",
    "    vision_encoder = replace_bn_with_gn(vision_encoder)\n",
    "\n",
    "    # ResNet18 has output dim of 512\n",
    "    vision_feature_dim = 512\n",
    "    # agent_pos is 2 dimensional\n",
    "    lowdim_obs_dim = 2\n",
    "    # observation feature has 514 dims in total per step\n",
    "    obs_dim = vision_feature_dim + lowdim_obs_dim\n",
    "    action_dim = 2\n",
    "\n",
    "    noise_pred_net = ConditionalUnet1D(\n",
    "        input_dim=action_dim,\n",
    "        global_cond_dim=obs_dim*obs_horizon\n",
    "    )\n",
    "    noise_pred_net = noise_pred_net.to(device)\n",
    "\n",
    "    nets = nn.ModuleList([vision_encoder, noise_pred_net]).to(device)\n",
    "\n",
    "    ema = EMAModel(\n",
    "        model=nets,\n",
    "        power=0.75)\n",
    "\n",
    "    noise_scheduler = DDPMScheduler(\n",
    "        num_train_timesteps=diffusion_timesteps,\n",
    "        beta_schedule='squaredcos_cap_v2',\n",
    "        clip_sample=True,\n",
    "        prediction_type='epsilon'\n",
    "    )\n",
    "\n",
    "    num_epochs = 100\n",
    "\n",
    "    optimizer = t.optim.AdamW(\n",
    "        params=nets.parameters(),\n",
    "        lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "    # Cosine LR schedule with linear warmup\n",
    "    lr_scheduler = get_scheduler(\n",
    "        name='cosine',\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=500,\n",
    "        num_training_steps=len(dataloader) * num_epochs\n",
    "    )\n",
    "\n",
    "    losses = []\n",
    "    for epoch in (e_iter := (range(num_epochs))):\n",
    "        for batch in (b_iter := (dataloader)):\n",
    "            actions = batch[\"action\"].to(device)\n",
    "            images = batch[\"image\"].to(device)\n",
    "            pos = batch[\"agent_pos\"].to(device)\n",
    "\n",
    "            encoded_vectors = vision_encoder(images.reshape(-1, 3, 96, 96))\n",
    "            encoded_vectors = encoded_vectors.reshape((images.shape[0], images.shape[1], -1))\n",
    "            context = t.cat([encoded_vectors, pos], dim=-1).reshape(images.shape[0], -1)\n",
    "\n",
    "            noise = t.randn(actions.shape, device=device)\n",
    "\n",
    "            timesteps = t.randint(0, diffusion_timesteps, (len(actions),), device=device)\n",
    "            noised_action = noise_scheduler.add_noise(actions, noise, timesteps)\n",
    "            noise_pred = noise_pred_net(noised_action, timesteps, global_cond=context)\n",
    "\n",
    "            loss = t.nn.functional.mse_loss(noise_pred, noise)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            lr_scheduler.step()\n",
    "            ema.step(noise_pred_net)\n",
    "            # b_iter.set_postfix({\"Loss\": loss.item()})\n",
    "            losses.append(loss.item())\n",
    "        print(losses[-1])\n",
    "    return losses, ema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72d7290a-a268-4cd1-bcae-900f3a1b2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\n",
    "        \"obs_horizon\": 1\n",
    "    },\n",
    "    {\n",
    "        \"obs_horizon\": 2\n",
    "    },\n",
    "    {\n",
    "        \"obs_horizon\": 3\n",
    "    },\n",
    "    {\n",
    "        \"obs_horizon\": 4\n",
    "    },\n",
    "    {\n",
    "        \"obs_horizon\": 5\n",
    "    },\n",
    "    {\n",
    "        \"obs_horizon\": 6\n",
    "    },\n",
    "    {\n",
    "        \"obs_horizon\": 7\n",
    "    },\n",
    "    {\n",
    "        \"obs_horizon\": 8\n",
    "    },\n",
    "    {\n",
    "        \"obs_horizon\": 9\n",
    "    },\n",
    "    {\n",
    "        \"obs_horizon\": 10\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64e3ff83-d765-4c4b-bb9a-cdc9322fb560",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "context has already been set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_start_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned/lib/python3.10/multiprocessing/context.py:247\u001b[0m, in \u001b[0;36mDefaultContext.set_start_method\u001b[0;34m(self, method, force)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_start_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actual_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force:\n\u001b[0;32m--> 247\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext has already been set\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m force:\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actual_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: context has already been set"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "if __name__ == '__main__':\n",
    "    mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "956d58d9-155b-449b-a357-c39c807ced38",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/data/vision/torralba/graphphys/miniconda3/envs/cloned/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/data/vision/torralba/graphphys/miniconda3/envs/cloned/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/data/vision/torralba/graphphys/miniconda3/envs/cloned/lib/python3.10/site-packages/parmap/parmap.py\", line 105, in _func_star_many\n    return func_items_args[0](*list(func_items_args[1]) + func_items_args[2],\n  File \"/tmp/ipykernel_1479392/1469527791.py\", line 147, in train_model\n    noise_pred_net = noise_pred_net.to(device)\n  File \"/data/vision/torralba/graphphys/miniconda3/envs/cloned/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 989, in to\n    return self._apply(convert)\n  File \"/data/vision/torralba/graphphys/miniconda3/envs/cloned/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n    module._apply(fn)\n  File \"/data/vision/torralba/graphphys/miniconda3/envs/cloned/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n    module._apply(fn)\n  File \"/data/vision/torralba/graphphys/miniconda3/envs/cloned/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n    module._apply(fn)\n  [Previous line repeated 3 more times]\n  File \"/data/vision/torralba/graphphys/miniconda3/envs/cloned/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 664, in _apply\n    param_applied = fn(param)\n  File \"/data/vision/torralba/graphphys/miniconda3/envs/cloned/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 987, in convert\n    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n  File \"/data/vision/torralba/graphphys/miniconda3/envs/cloned/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 217, in _lazy_init\n    raise RuntimeError(\nRuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mparmap\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparmap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned/lib/python3.10/site-packages/parmap/parmap.py:317\u001b[0m, in \u001b[0;36mstarmap\u001b[0;34m(function, iterables, *args, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(function, iterables, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;124;03m\"\"\" Equivalent to:\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m            >>> return ([function(x1,x2,x3,..., args[0], args[1],...) for\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;124;03m            >>>         (x1,x2,x3...) in iterable])\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m       :type pm_pbar: bool or dict\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_or_starmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstarmap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned/lib/python3.10/site-packages/parmap/parmap.py:238\u001b[0m, in \u001b[0;36m_map_or_starmap\u001b[0;34m(function, iterable, args, kwargs, map_or_starmap)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m     result \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39mmap_async(func_star,\n\u001b[1;32m    233\u001b[0m                             \u001b[38;5;28mzip\u001b[39m(repeat(function),\n\u001b[1;32m    234\u001b[0m                                 iterable,\n\u001b[1;32m    235\u001b[0m                                 repeat(\u001b[38;5;28mlist\u001b[39m(args)),\n\u001b[1;32m    236\u001b[0m                                 repeat(kwargs)),\n\u001b[1;32m    237\u001b[0m                             chunksize)\n\u001b[0;32m--> 238\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m close_pool:\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned/lib/python3.10/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method"
     ]
    }
   ],
   "source": [
    "import parmap\n",
    "results = parmap.starmap(train_model, [(i, f\"cuda:{i//2}\") for i in range(1, 11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1182b862-fa50-4ee2-b000-373770db1320",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    train_model(obs_horizon=i, device=f\"cuda:{i//2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcf98e9a-81db-4751-8aa0-70a579891a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting parmap\n",
      "  Downloading parmap-1.6.0-py2.py3-none-any.whl (12 kB)\n",
      "Installing collected packages: parmap\n",
      "Successfully installed parmap-1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install parmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c145052-db05-4b3a-a9ac-97a9a5c5e8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
